import autogen
import requests
import json
import re


# AssistantAgent
assistant = autogen.AssistantAgent(
    name="assistant",
    llm_config={
        "model": "llama3.1",
        "api_type": "ollama",
        "client_host": "http://localhost:11434",
        "context_window": 4096
    }
)

# UserProxyAgent
user_proxy = autogen.UserProxyAgent(
    name="user_proxy",
    human_input_mode="NEVER",
    max_consecutive_auto_reply=10,
    is_termination_msg=lambda x: x.get("content", "").rstrip().endswith("TERMINATE"),
)

# VerifierAgent
verifier = autogen.AssistantAgent(
    name="verifier",
    llm_config={
        "model": "llama3.1",
        "api_type": "ollama",
        "client_host": "http://localhost:11434",
        "context_window": 4096
    }
)


def call_ollama_api(prompt):
    url = "http://localhost:11434/api/generate"
    headers = {"Content-Type": "application/json"}
    payload = {
        "model": "llama3.2:3b",
        "prompt": prompt,
        "stream": False
    }
    response = requests.post(url, headers=headers, data=json.dumps(payload))
    if response.status_code == 200:
        return response.json().get("response", "No response found")
    else:
        return f"Error: {response.status_code} - {response.text}"


if __name__ == "__main__":
    # Task description for the Assistant Agent
    task_description = (
        "Write a complete Python function named `calculate_average` that takes a list of numbers as input. "
        "It should validate the input to ensure all elements are numbers, handle empty lists gracefully, "
        "and return the average of the numbers. "
    )

    # Step 1: Generate the Python code
    print("Generating Python code...\n")
    api_response = call_ollama_api(task_description)
    print("Ollama API Response:\n", api_response)

    assistant_response = user_proxy.initiate_chat(
        assistant,
        message=task_description
    )
    print("Assistant Response:\n", assistant_response)

    # Extract the chat history content
    chat_history = assistant_response.chat_history
    if chat_history and len(chat_history) > 0:
        # Get the most recent content from the assistant's response
        last_response = chat_history[-1].get("content", "")
        print("Last Response:\n", last_response)

        # Extract the Python code block
        code_block_match = re.search(r'```python\n(.*?)```', last_response, re.DOTALL)
        if code_block_match:
            generated_code = code_block_match.group(1)
            print("Generated Code:\n", generated_code)

            # Step 2: Verify the code with the Verifier Agent
            verification_task = (
                f"The following Python code was generated by an assistant. Please verify its correctness by analyzing the logic, "
                f"validating input handling, and ensuring it includes proper error handling for empty lists and invalid inputs. "
                f"Provide specific feedback and suggestions for improvement:\n\n{assistant_response}"
            )
            verifier_response = user_proxy.initiate_chat(
                verifier,
                message=verification_task
            )
            print("Verifier Response:\n", verifier_response)
        else:
            print("No valid Python code block found in the assistant's response.")
    else:
        print("No chat history found in the assistant's response.")